========================
 HDT Library and Tools.
========================

Copyright (C) 2012, Mario Arias, Javier D. Fernandez, Miguel A. Martinez-Prieto
All rights reserved.

This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA

Visit our Web Page: www.rdfhdt.org

Contacting the authors:
 Mario Arias:               mario.arias@deri.org
 Javier D. Fernandez:       jfergar@infor.uva.es
 Miguel A. Martinez-Prieto: migumar2@infor.uva.es


Overview
=================

HDT-lib is a C++ library that implements the W3C Submission (http://www.w3.org/Submission/2011/03/) of the RDF HDT (Header-Dictionary-Triples) binary format for publishing and exchanging RDF data at large scale. Its compact representation allows storing RDF in fewer space, while providing direct access to the stored information. This is achieved by depicting the RDF graph in terms of three main components: Header, Dictionary and Triples. The Header includes extensible metadata required to describe the RDF data set and details of its internals. The Dictionary organizes the vocabulary of strings present in the RDF graph by assigning numerical IDs to each different string. The Triples component depicts the structure of the underlying graph in a compressed form.

The distribution provides two components:
- C++ library itself: Provides an API to use HDT files programmatically. It allows creating HDT files from RDF and converting HDT files back to RDF. It also provides a Search interface to find triples that match a specific triple pattern.
- Command line tools: Allow to convert between RDF and HDT, and also perform searches against HDT files.


Compiling
=================
Dependencies: 
	*Libcds (http://libcds.recoded.cl/) We use a modified fork of libcds that is included with the distribution.
	*(Optional) Raptor RDF Parser Library Version 2+  (for more information see: http://http://librdf.org/raptor/)
		Note: Without Raptor the library is only capable of importing and exporting RDF in NTriples format.
	*(Optional) Kyoto Cabinet. Allows to convert very big RDF files on machines with limited amount of main memory.
	*(Optional) Libz. Allows to load files in ntriples compressed with GZIP (i.e. file.nt.gz)

Edit Makefile uncommenting these lines to include compile support for the optional libraries:
#RAPTOR_SUPPORT=true
#KYOTO_SUPPORT=true
#LIBZ_SUPPORT=true

Compile:
	Run `make` under hdt-lib to compile the library and tools.


Command line tools
=================

The tool provides three main command line tools:

** The tool rdf2hdt converts an RDF file to HDT format. The format of the input file will be NTriples by default, although it can be set by using the "-f" (format) flag. It is also possible to fine tune the internal format of the HDT file using a configfile. Several configfile examples are provided under the directory "presets" of the distribution.

$ rdf2hdt [options] <RDF input file> <HDT output file> 
	-h			This help
	-i		Also generate index to solve all triple patterns.
	-c	<configfile>	HDT Config options file
	-o	<options>	HDT Additional options (option1=value1;option2=value2;...)
	-f	<format>	Format of the RDF input (ntriples, nquad, n3, turtle, rdfxml)
	-B	"<base URI>"	Base URI of the dataset.


** The tool hdt2rdf converts an HDT file back to RDF in the specified format. If not format specified, NTriples will be used.

$ hdt2rdf [options] <HDT input file> <RDF output file> 
	-h			This help
	-f	<format>	RDF Format of the output


** The tool hdtSearch allows to search triple patterns against an HDT file. For example, to list all patterns, one can use the "? ? ?" query. To search all information about <myns:subject1> one can use "<myns:subject1> ? ?"

$ hdtSearch [options] <hdtfile> 
	-h			This help
	-q	<query>	Launch query and exit.
	-o	<output>	Save query output to file.

>> ? ? ?
............. // List of all triples


** The tool hdtInfo extracts the header from an HDT file.

$ hdtInfo <hdtFile>

** The tool replaceHeader replaces the header of an HDT with the supplied one. You can use hdtInfo to extract the existing one, edit it, and then use replaceHeader to update to the new one. Note: you need to specify a different input and output HDT file.

$ replaceHeader <originalHDTfile> <newHDTfile> <newHeader>


Usage example
=================

After installation, run:

# This creates the HDT representation
$ tools/rdf2hdt data/test.nt data/test.hdt

# This converts back the HDT to RDF.
$ tools/hdt2rdf data/test.hdt data/test.hdtexport.nt

# This allows browsing a dataset interactively.
$ tools/hdtSearch data/test.hdt

>> ? ? ?
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri4>
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri5>
<http://example.org/uri1> <http://example.org/predicate1> "literal1"
<http://example.org/uri1> <http://example.org/predicate1> "literalA"
<http://example.org/uri1> <http://example.org/predicate1> "literalB"
<http://example.org/uri1> <http://example.org/predicate1> "literalC"
<http://example.org/uri1> <http://example.org/predicate2> <http://example.org/uri3>
<http://example.org/uri1> <http://example.org/predicate2> <http://example.org/uriA3>
<http://example.org/uri2> <http://example.org/predicate1> "literal1"
9 results shown.

>> <http://example.org/uri3> ? ?
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri4>
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri5>
2 results shown.

>> exit

# You can also dump the results of a query to a file
$ tools/hdtSearch -q "? <http://example.org/predicate1> ?" data/test.hdt > output.txt

# To browse the header of an HDT file:
$ tools/hdtInfo data/test.hdt

USING THE LIBRARY
=================

This section shows how to use the HDT Library programmatically from C++ in your own application. 

// Creating an HDT file.

#include <HDTManager.hpp>

using namespace hdt;

int main() {

	HDTSpecification spec;
	
	// Read RDF into an HDT file.
 	HDT *hdt = HDTManager::generateHDT("data/test.nt", "http://example.org/test", NTRIPLES, spec);

	// Save HDT to a file
	hdt->saveToHDT("data/test.hdt");

	delete hdt;
}


// Load an HDT file and query.

#include <iostream>
#include <HDTManager.hpp>

using namespace std;
using namespace hdt;

int main() {

	// Load HDT file
	HDT *hdt = HDTManager::mapHDT("data/test.hdt");

	// Enumerate all triples matching a pattern ("" means any)
	IteratorTripleString *iterator = hdt->search("<http://example.org/uri3>","","");
	while(it->hasNext()){
		TripleString triple = it->next();
		cout << "Result: " << triple.getSubject() << ", " << triple.getPredicate() << ", " << triple.getObject() << endl;
	}
	delete iterator;
	
	// Enumerate all different predicates
	cout << "Dataset contains " << hdt->getDictionary()->getNpredicates() << " predicates.";
	IteratorUCharString *itPred = hdt->getDictionary()->getPredicates();
	while(itPred->hasNext()) {
		uchar *str = itPred->next(); // Warning this pointer is only valid until next call to next();
		cout << str << endl;
		itPred->freeStr(str);
	}
	delete itPred;
	
	delete hdt;
}
